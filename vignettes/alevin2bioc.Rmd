---
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    toc_depth: 3
    fig_width: 5
bibliography: "`r file.path(system.file(package='alevin2bioc', 'vignettes'), 'library.bib')`"
vignette: >
  %\VignetteIndexEntry{alevin2bioc}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding[utf8]{inputenc}
---

# Tutorial for importing alevin scRNA-seq quantifications into R/Bioconductor

## Instructor(s) name(s) and contact information

[Michael Love](https://mikelove.github.io),
[Avi Srivastava](https://k3yavi.github.io)

## Introduction

*alevin* is a method for ... [@alevin]. It extends the methods in the
*Salmon* software [@salmon].

The data we will use is ... (citation).

## Running alevin

In order to run *alevin*, we must first ...

Instructions on downloading *alevin* can be found here ...

Instructions on indexing a set of reference transcripts can be found
here ... For this experiment, we used the 
[GENCODE](https://www.gencodegenes.org/) 
human reference transcripts [@gencode].

## Importing alevin data with tximeta

We will use *tximeta* ... [@tximeta].

First we specify the path where the quantification data is stored. In
this tutorial, the data is stored in an R package, so we need to use
the `system.file` command. For typical use, you would not use
`system.file`, but would just specify the path to the directory of the
output from *alevin*. 

```{r}
# normally you just would use:
# dir <- "/path/to/alevin/output"
extdata <- system.file("extdata", package="alevin2bioc")
dir <- file.path(extdata, "pbmc_1k")
```

```{r}
files <- file.path(dir, "alevin", "quants_mat.gz")
file.exists(files)
```

```{r echo=FALSE}
suppressPackageStartupMessages(library(GenomicFeatures))
```

We can import the *alevin* quantification using the following call to
`tximeta`. The extra argument to *alevin* will filter out cells based
on *alevin*'s post-quantification quality control methods (see paper
for details).

```{r}
library(tximeta)
se <- tximeta(files, type="alevin", alevinArgs=list(filterBarcodes=TRUE))
```

`tximeta` returns a *SummarizedExperiment* [@Lawrence2013]. We can
easily convert this object into a *SingleCellExperiment*
[@Amezquita2020] which has specific slots designed for single-cell
experiment data.

```{r}
suppressPackageStartupMessages(library(SingleCellExperiment))
sce <- as(se, "SingleCellExperiment")
```

## Benefits of tximeta

We can automatically add IDs, because *tximeta* knows the type of
identifiers on the rows of the `sce` object:

```{r}
library(org.Hs.eg.db)
sce <- addIds(sce, "SYMBOL")
```

```{r}
mcols(sce)
```

Also, because the provenance was detected, we also have the ranges of
the genes in their proper genomic context. So it is easy to find, for
example, genes near a particular position in the genome, in this case
4 genes that overlap the range `chr1:10,000,000-10,100,000`.

```{r}
x <- GRanges("chr1", IRanges(10e6,10.1e6))
sce[sce %over% x,]
```

## Add cell annotations

Cell annotations were generated using *Seurat* [@seurat]. The script is
saved in this package in `inst/scripts/seurat.R`.

```{r}
ids <- readRDS(file.path(extdata, "idents.rds"))
top10 <- read.csv(file.path(extdata, "top10.csv"))
```

```{r}
idx <- colnames(sce) %in% names(ids)
table(idx)
sce <- sce[,idx]
sce$cluster <- ids[colnames(sce)]
```

```{r}
table(sce$cluster)
```

Note that the different clusters have different total counts, for
example:

```{r}
cs <- colSums(assays(sce)[["counts"]])
# cells with higher number of UMI
more.umi <- cs > 10000
(tab <- table(more.umi, sce$cluster))
100 * round(prop.table(tab,2),2) # percent
# cell with lower number of UMI
fewer.umi <- cs < 5000
(tab <- table(fewer.umi, sce$cluster))
100 * round(prop.table(tab,2),2) # percent
```

```{r}
head(top10)
```

## Plotting counts with uncertainty

For a later demonstration of scaling, we will sort the cells by the
total count (this is not something you would necessarily do in a
typical analysis).

```{r}
o <- order(colSums(assays(sce)[["counts"]]), decreasing=TRUE)
sce <- sce[,o]
```

```{r plot-basic}
library(fishpond)
plotInfReps(sce, idx="ENSG00000167286.9",
            x="cluster", mainCol="SYMBOL",
            legend=TRUE)
```

```{r plot-medium}
plotInfReps(sce[,sample(ncol(sce),200)],
            idx="ENSG00000167286.9",
            x="cluster", mainCol="SYMBOL",
            legend=TRUE)
```

```{r plot-small}
plotInfReps(sce[,sample(ncol(sce),100)],
            idx="ENSG00000167286.9",
            x="cluster", mainCol="SYMBOL",
            legend=TRUE)
```

```{r plot-no-order}
plotInfReps(sce, idx="ENSG00000167286.9",
            x="cluster", mainCol="SYMBOL",
            reorder=FALSE)
```

## Scaling with size factors

We use `computeSumFactors` [@Lun2016] from the *scran* package
[@scran] ...

```{r size-factors}
library(scran)
sce <- computeSumFactors(sce, clusters=sce$cluster)
plot(cs, sizeFactors(sce), xlab="column sum", ylab="sum factor")
```

```{r scaling}
par(mfrow=c(2,1), mar=c(2.5,4.5,1,1))
plotInfReps(sce, idx="ENSG00000167286.9",
            x="cluster", main="",
            reorder=FALSE)
plotInfReps(sce, idx="ENSG00000167286.9",
            x="cluster", main="",
            applySF=TRUE, reorder=FALSE)
```

## Inferential variance (uncertainty)

Inferential variance is a focus of the *Swish* nonparametric
statistical method [@swish] which we do not demonstrate here ...

```{r}
var <- as.vector(assays(sce)[["variance"]])
mu <- as.vector(assays(sce)[["mean"]])
idx <- mu > 3
df <- data.frame(log10mean=log10(mu[idx]),
                 log10var=log10(var[idx]))
```

```{r var-mean, fig.height=4}
library(ggplot2)
ggplot(df, aes(log10mean, log10var)) +
  geom_hex(bins=100) + 
  geom_abline(intercept=0, slope=1, col="red")
```

```{r}
rratio <- rowMeans(assays(sce)[["variance"]] /
                   (assays(sce)[["mean"]] + 1))
rmu <- rowMeans(assays(sce)[["mean"]])
idx <- rmu > 3
df <- data.frame(log10mean=log10(rmu[idx]),
                 rratio=rratio[idx],
                 gene=mcols(sce)$SYMBOL[idx])
```

```{r high-var-mean-ratio}
with(df, plot(log10mean, rratio))
high.uncert <- c(187,188)
with(df[high.uncert,],
     points(log10mean, rratio, pch=20, col="red"))
with(df[high.uncert,],
     text(log10mean, rratio, gene, pos=4))
mcols(sce)$SYMBOL[idx][c(668,669)]
```

Read-through of nearby gene `ENSG00000265681.7` (RPL17):

```{r plot-high-uncert-rd}
plotInfReps(sce[,1:100], idx="ENSG00000215472.10",
            x="cluster", mainCol="SYMBOL")
```

```{r plot-high-uncert-gene}
plotInfReps(sce[,1:100], idx="ENSG00000265681.7",
            x="cluster", mainCol="SYMBOL")
```

## Downstream analysis with Seurat

We now load *Seurat* [@seurat] ...

```{r}
library(Seurat)
cts <- assays(sce)[["counts"]]
pbmc <- CreateSeuratObject(cts)
```

```{r seurat-violin}
mt.genes <- rownames(sce)[as.logical(seqnames(sce) == "chrM")]
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, features=mt.genes)
feats <- c("nFeature_RNA", "nCount_RNA", "percent.mt")
VlnPlot(pbmc, features=feats, ncol=3)
```

## Links for further reading

## References
